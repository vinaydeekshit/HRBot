# Use an official Python runtime as a parent image
FROM python:3.10-slim

# Set the working directory in the container
WORKDIR /app

# Install necessary system dependencies for curl, spaCy, and others
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    gcc \
    libffi-dev \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Install Ollama (replace with actual installation command if different)
RUN curl -sSL https://ollama.com/download | bash

# Download the Llama3.2 model (assumes Ollama CLI works in the container)
RUN /bin/bash -c "ollama pull llama3.2:latest"

# Copy the requirements.txt file into the container
COPY requirements.txt . 

# Install Python dependencies from the requirements file
RUN pip install --no-cache-dir -r requirements.txt

# Download and install the spaCy language model (en_core_web_sm)
RUN python -m spacy download en_core_web_sm

# Copy the rest of the application code into the container
COPY . .

# Expose port 5000 (Flask default port)
EXPOSE 5000

# Set environment variables (optional)
ENV FLASK_ENV=production

# Start Ollama and then the Flask application with Gunicorn
CMD /bin/bash -c "ollama start && gunicorn -w 4 -b 0.0.0.0:5000 app:app"
